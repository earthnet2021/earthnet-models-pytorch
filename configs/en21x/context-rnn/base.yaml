Architecture: "local-rnn"

Seed: 42

Setting: "en21x"

Logger:
    save_dir: "experiments/"

Checkpointer:
    save_top_k: 1
    save_last: True
    every_n_epochs: 1

Trainer:
    gpus: [1,] #6
    strategy: 'ddp'
    #deterministic: True
    log_every_n_steps: 32
    #profiler: 'advanced'
    #fast_dev_run: True
    #log_gpu_memory: 'all'
    #weights_summary: 'full'
    max_epochs: 100
    #limit_train_batches: 32
    #limit_val_batches: 32
    gradient_clip_val: 1
    val_check_interval: 0.25
  
Data:
    base_dir: "/Net/Groups/BGI/work_1/scratch/s3/earthnet/earthnet2021x/"
    test_track: "iid"
    train_batch_size: 16 #96
    val_batch_size: 4
    test_batch_size: 4 #96
    num_workers: 8 #2

Task:
    loss:
        name: "MaskedL2NDVILoss"
        min_lc: 10
        max_lc: 30
        ndvi_pred_idx: 0
        ndvi_targ_ix: 0
        pred_mask_value: -1
    context_length: 10
    target_length: 20
    n_stochastic_preds: 1
    optimization:
        optimizer:
            - 
                name: AdamW
                args: 
                    betas: [0.9, 0.999]
                lr_per_sample: 0.000001
        lr_shedule:
            -
                name: MultiStepLR
                args:
                    milestones: [60,90] #[2, 20, 50, 90]
                    gamma: 0.1
    n_log_batches: 2
    compute_metric_on_test: True

Model:
    state_encoder_name: FPN
    state_encoder_args: 
        encoder_name: timm-efficientnet-b0
        encoder_weights: noisy-student
        in_channels: 55
        classes: 128
        decoder_merge_policy: cat
        decoder_dropout: 0
    update_encoder_name: MLP
    update_encoder_inchannels: 88
    update_encoder_nclasses: 64
    train_lstm_npixels: 512
    lc_min: 10
    lc_max: 30
    val_n_splits: 20
